{"cells":[{"cell_type":"markdown","source":["# Preprocessing Steps for Head Pose Videos\n","\n","This notebook is for extracting mesh features from `.webm` videos generated by the head pose recording experiment. The result of running this pipeline is a `.json` file for each subject/session in the head pose experiment."],"metadata":{"id":"3ll-npHHozPw"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53048,"status":"ok","timestamp":1658252861085,"user":{"displayName":"Oliravan Eswaramoorthy","userId":"13611592422418692717"},"user_tz":240},"id":"cfqjWhd5yEcu","outputId":"c575bf6a-c52f-4582-b958-81e3ed046786"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n","\u001b[K     |████████████████████████████████| 32.9 MB 2.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.1.0)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.10.1\n","Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import cv2\n","import os\n","import fnmatch\n","import json\n","!pip install mediapipe\n","import mediapipe as mp\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"yWZgrC25wQG3"},"source":["# Configure MediaPipe FaceMesh\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wLLQ1YZvZGF"},"outputs":[],"source":["mp_face_mesh = mp.solutions.face_mesh\n","face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)"]},{"cell_type":"markdown","metadata":{"id":"2x-nnHcut9-_"},"source":["# Process Video Pipeline"]},{"cell_type":"markdown","source":["Define the function to take in a `path` to a video file and output an array of shape (`frames`, `landmarks`, `3`), where `frames` is the number of frames in the video file, `landmarks` is the number of landmarks extracted by the face mesh model, and `3` corresponds to the `x`, `y`, and `z` coordinates for each landmark."],"metadata":{"id":"S21h5wcMpeAx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DedTOFtRuDF_"},"outputs":[],"source":["def extract_mesh_from_video(path):\n","  # open a video file for video capturing\n","  cap = cv2.VideoCapture(path)\n","  out = []\n","  \n","  # to see if video capturing has been initialized\n","  while(cap.isOpened()):\n","    # return (1) if any frames grabbed (2) grabbed image (empty if ret is false)\n","    ret, frame = cap.read()\n","    # Q: why frame could be none?\n","    if frame is not None:\n","      # process an RGB image and returns the face landmarks on each detected face\n","      results = face_mesh.process(frame)\n","      # check if any faces detected\n","      if not results.multi_face_landmarks:\n","        continue\n","      landmarks = results.multi_face_landmarks[0].landmark\n","      # store landmarks as an array of arrays\n","      lm = [[a.x, a.y, a.z] for a in landmarks]\n","      # 3D tensor that stores landmarks frame by frame\n","      out.append(lm)\n","    else:\n","      break\n","\n","  if len(out) > 0:\n","    out = np.reshape(np.array(out), (len(out), -1, 3)).tolist()\n","  return out"]},{"cell_type":"markdown","source":["Run through all of the video files in the folder and process their data. If `.json` output already exists for the subject ID, then skip processing. (To overwrite existing data, delete the corresponding `.json` file before running this step.)"],"metadata":{"id":"JbGpX4Hnp7EL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":426409,"status":"ok","timestamp":1658253287478,"user":{"displayName":"Oliravan Eswaramoorthy","userId":"13611592422418692717"},"user_tz":240},"id":"soMq474-143F","outputId":"c9e95e77-8cb9-4d25-f238-e86dab0f7b73"},"outputs":[{"output_type":"stream","name":"stdout","text":["56\n","{'cmxk63s9', 'pvryvfwa', 'cwt70a0t', 'k1ofdrbc', '1ze2lppo', 'dglf69wf', '9d9vbql0', 'w9v7s1qs', 'tge4y8ud', '2suq3xfy', 'yj7dyk2e', 'lhrhyyon', 'vrx1gw70', '26n5e9ov', '2qxwc8jg', 'trpy4s76', 'u1k9g5s0', 'myj2adhw', 'q07qdfbn', 'kxeoqbnd', 'c56h6n8x', 'bor9krjs', 'y1su0hzk', 'rdgs44u1', '0phtxs0b', '6hdlxqjp', '095e0k9q', 'stp5srte', 'lxbcmkkp', 'f35x3ycv', 'q9f3nczs', '76u9jwyr', 'ef1w751t', 'lkww796q', '03r8jhv6', 'nrw7klk6', 'f1z4jwv2', 'k1w0pgny', '1yt83duh', 'bcafboa7', 'nok0norz', '37gnx93o', '2yrcw5xy', '464qojj0', 'bxjgo5x9', 'shvb0ync', 'dvmwxexg', 'nwwz56wd', '0rl41qzs', '1776mmn2', 'zzxpetp1', 's7e192r1', 'tvrkm302', 'gjq0x5c8', '7rym69s3', 'unbhythd'}\n","cmxk63s9\n","pvryvfwa\n","cwt70a0t\n","k1ofdrbc\n","1ze2lppo\n","dglf69wf\n","9d9vbql0\n","w9v7s1qs\n","tge4y8ud\n","2suq3xfy\n","yj7dyk2e\n","lhrhyyon\n","vrx1gw70\n","26n5e9ov\n","2qxwc8jg\n","trpy4s76\n","u1k9g5s0\n","myj2adhw\n","q07qdfbn\n","kxeoqbnd\n","c56h6n8x\n","bor9krjs\n","y1su0hzk\n","rdgs44u1\n","0phtxs0b\n","6hdlxqjp\n","095e0k9q\n","stp5srte\n","lxbcmkkp\n","f35x3ycv\n","q9f3nczs\n","76u9jwyr\n","ef1w751t\n","lkww796q\n","03r8jhv6\n","nrw7klk6\n","f1z4jwv2\n","k1w0pgny\n","1yt83duh\n","bcafboa7\n","nok0norz\n","37gnx93o\n","2yrcw5xy\n","464qojj0\n","bxjgo5x9\n","shvb0ync\n","dvmwxexg\n","nwwz56wd\n","0rl41qzs\n","1776mmn2\n","zzxpetp1\n","s7e192r1\n","tvrkm302\n","gjq0x5c8\n","7rym69s3\n","unbhythd\n"]}],"source":["# get the path of the webm file\n","path = '/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/webm_pose/'\n","\n","# store all the file directories\n","all_files = os.listdir(path)\n","print(len(all_files))\n","\n","# get unique subjects\n","unique_subjects = set([filepath.split('_')[0] for filepath in os.listdir(path)])\n","print(unique_subjects)\n","\n","for subject in unique_subjects:\n","  all_data = {}\n","\n","  print(subject)\n","\n","  # check if the subject json file already exists. if so, skip the remainning body\n","  if os.path.isfile('/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/json_pose/'+subject+'.json'):\n","    continue\n","   \n","  subject_data = []\n","  # go through all file directories in the webm file, find those that start with the subject name\n","  subject_files = fnmatch.filter(all_files, subject+'*')\n","  # manage every single file directory that starts with the subject name\n","  for filename in subject_files:\n","    # transform file name into an array\n","    fileinfo = filename.replace('.','_').split('_')\n","    # store relevant values\n","    subject = fileinfo[0]\n","    meshfeatures = extract_mesh_from_video(path + filename)\n","    # create and append a dictionary to the exisiting array\n","    subject_data.append({\n","        'features': meshfeatures \n","    })\n","  # once the last for loop is over, assign the subject_data array as the value to the subject key\n","  all_data[subject] = subject_data\n","\n","  # export the json file for the subject to the drive\n","  with open('/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/json_pose/'+subject+'.json', 'w') as file:\n","    json.dump(all_data, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1658253287479,"user":{"displayName":"Oliravan Eswaramoorthy","userId":"13611592422418692717"},"user_tz":240},"id":"UneHehSTmjrl","outputId":"a3453ebb-fa15-495b-fd89-933fe8dd5aec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'03r8jhv6',\n"," '095e0k9q',\n"," '0phtxs0b',\n"," '0rl41qzs',\n"," '1776mmn2',\n"," '1yt83duh',\n"," '1ze2lppo',\n"," '26n5e9ov',\n"," '2qxwc8jg',\n"," '2suq3xfy',\n"," '2yrcw5xy',\n"," '37gnx93o',\n"," '464qojj0',\n"," '6hdlxqjp',\n"," '76u9jwyr',\n"," '7rym69s3',\n"," '9d9vbql0',\n"," 'bcafboa7',\n"," 'bor9krjs',\n"," 'bxjgo5x9',\n"," 'c56h6n8x',\n"," 'cmxk63s9',\n"," 'cwt70a0t',\n"," 'dglf69wf',\n"," 'dvmwxexg',\n"," 'ef1w751t',\n"," 'f1z4jwv2',\n"," 'f35x3ycv',\n"," 'gjq0x5c8',\n"," 'k1ofdrbc',\n"," 'k1w0pgny',\n"," 'kxeoqbnd',\n"," 'lhrhyyon',\n"," 'lkww796q',\n"," 'lxbcmkkp',\n"," 'myj2adhw',\n"," 'nok0norz',\n"," 'nrw7klk6',\n"," 'nwwz56wd',\n"," 'pvryvfwa',\n"," 'q07qdfbn',\n"," 'q9f3nczs',\n"," 'rdgs44u1',\n"," 's7e192r1',\n"," 'shvb0ync',\n"," 'stp5srte',\n"," 'tge4y8ud',\n"," 'trpy4s76',\n"," 'tvrkm302',\n"," 'u1k9g5s0',\n"," 'unbhythd',\n"," 'vrx1gw70',\n"," 'w9v7s1qs',\n"," 'y1su0hzk',\n"," 'yj7dyk2e',\n"," 'zzxpetp1'}"]},"metadata":{},"execution_count":5}],"source":["unique_subjects"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}