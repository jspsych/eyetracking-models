{"cells":[{"cell_type":"markdown","source":["# Preprocessing Steps for Eye Data Videos\n","\n","This notebook is for extracting mesh features from `.webm` videos generated by the `eyedata` experiment. The result of running this pipeline is a `.json` file for each subject/session in the `eyedata` experiment."],"metadata":{"id":"3ll-npHHozPw"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30157,"status":"ok","timestamp":1656558179516,"user":{"displayName":"Shunji Wan","userId":"11173786701409222850"},"user_tz":240},"id":"cfqjWhd5yEcu","outputId":"4ee4d72c-bc28-4371-f6eb-46fcc70b83dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n","\u001b[K     |████████████████████████████████| 32.9 MB 83.0 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.1.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.10.1\n","Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import cv2\n","import os\n","import fnmatch\n","import json\n","!pip install mediapipe\n","import mediapipe as mp\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"yWZgrC25wQG3"},"source":["# Configure MediaPipe FaceMesh\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wLLQ1YZvZGF"},"outputs":[],"source":["mp_face_mesh = mp.solutions.face_mesh\n","face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)"]},{"cell_type":"markdown","metadata":{"id":"2x-nnHcut9-_"},"source":["# Process Video Pipeline"]},{"cell_type":"markdown","source":["Define the function to take in a `path` to a video file and output an array of shape (`frames`, `landmarks`, `3`), where `frames` is the number of frames in the video file, `landmarks` is the number of landmarks extracted by the face mesh model, and `3` corresponds to the `x`, `y`, and `z` coordinates for each landmark."],"metadata":{"id":"S21h5wcMpeAx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DedTOFtRuDF_"},"outputs":[],"source":["def extract_mesh_from_video(path):\n","  # open a video file for video capturing\n","  cap = cv2.VideoCapture(path)\n","  out = []\n","  \n","  # to see if video capturing has been initialized\n","  while(cap.isOpened()):\n","    # return (1) if any frames grabbed (2) grabbed image (empty if ret is false)\n","    ret, frame = cap.read()\n","    # Q: why frame could be none?\n","    if frame is not None:\n","      # process an RGB image and returns the face landmarks on each detected face\n","      results = face_mesh.process(frame)\n","      # check if any faces detected\n","      if not results.multi_face_landmarks:\n","        continue\n","      landmarks = results.multi_face_landmarks[0].landmark\n","      # store landmarks as an array of arrays\n","      lm = [[a.x, a.y, a.z] for a in landmarks]\n","      # 3D tensor that stores landmarks frame by frame\n","      out.append(lm)\n","    else:\n","      break\n","\n","  if len(out) > 0:\n","    out = np.reshape(np.array(out), (len(out), -1, 3)).tolist()\n","  return out"]},{"cell_type":"markdown","source":["Run through all of the video files in the folder and process their data. If `.json` output already exists for the subject ID, then skip processing. (To overwrite existing data, delete the corresponding `.json` file before running this step.)"],"metadata":{"id":"JbGpX4Hnp7EL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":698,"status":"ok","timestamp":1656558201345,"user":{"displayName":"Shunji Wan","userId":"11173786701409222850"},"user_tz":240},"id":"soMq474-143F","outputId":"37f62067-4127-407b-e8f9-2e62558a2e71"},"outputs":[{"output_type":"stream","name":"stdout","text":["1277\n","{'c4g2mw61', '27o23haf', '7asl4wbk', 'v2sfzuft', 'fwkruums', 'g1klo888', '1lzaw0tb', 'k6yrzzo1', 'lyln56b2', 'j72zjd8w'}\n","c4g2mw61\n","27o23haf\n","7asl4wbk\n","v2sfzuft\n","fwkruums\n","g1klo888\n","1lzaw0tb\n","k6yrzzo1\n","lyln56b2\n","j72zjd8w\n"]}],"source":["# get the path of the webm file\n","path = '/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/webm/'\n","\n","# store all the file directories\n","all_files = os.listdir(path)\n","print(len(all_files))\n","\n","# get unique subjects\n","unique_subjects = set([filepath.split('_')[0] for filepath in os.listdir(path)])\n","print(unique_subjects)\n","\n","for subject in unique_subjects:\n","  all_data = {}\n","\n","  print(subject)\n","\n","  # check if the subject json file already exists. if so, skip the remainning body\n","  if os.path.isfile('/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/json/'+subject+'.json'):\n","    continue\n","   \n","  subject_data = []\n","  # go through all file directories in the webm file, find those that start with the subject name\n","  subject_files = fnmatch.filter(all_files, subject+'*')\n","  # manage every single file directory that starts with the subject name\n","  for filename in subject_files:\n","    # transform file name into an array\n","    fileinfo = filename.replace('.','_').split('_')\n","    # store relevant values\n","    subject = fileinfo[0]\n","    block = fileinfo[1]\n","    phase = fileinfo[2]\n","    x = fileinfo[3]\n","    y = fileinfo[4]\n","    meshfeatures = extract_mesh_from_video(path + filename)\n","    # create and append a dictionary to the exisiting array\n","    subject_data.append({\n","        'block': block,\n","        'phase': phase,\n","        'x': x,\n","        'y': y,\n","        'features': meshfeatures \n","    })\n","  # once the last for loop is over, assign the subject_data array as the value to the subject key\n","  all_data[subject] = subject_data\n","\n","  # export the json file for the subject to the drive\n","  with open('/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/json/'+subject+'.json', 'w') as file:\n","    json.dump(all_data, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84,"status":"ok","timestamp":1656558204661,"user":{"displayName":"Shunji Wan","userId":"11173786701409222850"},"user_tz":240},"id":"UneHehSTmjrl","outputId":"e142c159-1463-45d4-ce99-570393cdc324"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'1lzaw0tb',\n"," '27o23haf',\n"," '7asl4wbk',\n"," 'c4g2mw61',\n"," 'fwkruums',\n"," 'g1klo888',\n"," 'j72zjd8w',\n"," 'k6yrzzo1',\n"," 'lyln56b2',\n"," 'v2sfzuft'}"]},"metadata":{},"execution_count":7}],"source":["unique_subjects"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}