{"cells":[{"cell_type":"markdown","source":["# Preprocessing Steps for Eye Data Videos\n","\n","This notebook is for extracting mesh features from `.webm` videos generated by the `eyedata` experiment. The result of running this pipeline is a `.json` file for each subject/session in the `eyedata` experiment."],"metadata":{"id":"3ll-npHHozPw"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39571,"status":"ok","timestamp":1669756557579,"user":{"displayName":"Oliravan Eswaramoorthy","userId":"13611592422418692717"},"user_tz":300},"id":"cfqjWhd5yEcu","outputId":"e0d7e520-a4ca-4db4-d5f3-a625a6cda116"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n","\u001b[K     |████████████████████████████████| 33.0 MB 143 kB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.19.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.3.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (22.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mediapipe) (1.15.0)\n","Installing collected packages: flatbuffers, mediapipe\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.11.23 which is incompatible.\u001b[0m\n","Successfully installed flatbuffers-22.11.23 mediapipe-0.9.0\n","Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import cv2\n","import os\n","import fnmatch\n","import json\n","!pip install mediapipe\n","import mediapipe as mp\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"yWZgrC25wQG3"},"source":["# Configure MediaPipe FaceMesh\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wLLQ1YZvZGF"},"outputs":[],"source":["mp_face_mesh = mp.solutions.face_mesh\n","face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)"]},{"cell_type":"markdown","metadata":{"id":"2x-nnHcut9-_"},"source":["# Process Video Pipeline"]},{"cell_type":"markdown","source":["Define the function to take in a `path` to a video file and output an array of shape (`frames`, `landmarks`, `3`), where `frames` is the number of frames in the video file, `landmarks` is the number of landmarks extracted by the face mesh model, and `3` corresponds to the `x`, `y`, and `z` coordinates for each landmark."],"metadata":{"id":"S21h5wcMpeAx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DedTOFtRuDF_"},"outputs":[],"source":["def extract_mesh_from_video(path):\n","  # open a video file for video capturing\n","  cap = cv2.VideoCapture(path)\n","  out = []\n","  \n","  # to see if video capturing has been initialized\n","  while(cap.isOpened()):\n","    # return (1) if any frames grabbed (2) grabbed image (empty if ret is false)\n","    ret, frame = cap.read()\n","    # Q: why frame could be none?\n","    if frame is not None:\n","      # process an RGB image and returns the face landmarks on each detected face\n","      results = face_mesh.process(frame)\n","      # check if any faces detected\n","      if not results.multi_face_landmarks:\n","        continue\n","      landmarks = results.multi_face_landmarks[0].landmark\n","      # store landmarks as an array of arrays\n","      lm = [[a.x, a.y, a.z] for a in landmarks]\n","      # 3D tensor that stores landmarks frame by frame\n","      out.append(lm)\n","    else:\n","      break\n","\n","  if len(out) > 0:\n","    out = np.reshape(np.array(out), (len(out), -1, 3)).tolist()\n","  return out"]},{"cell_type":"markdown","source":["Run through all of the video files in the folder and process their data. If `.json` output already exists for the subject ID, then skip processing. (To overwrite existing data, delete the corresponding `.json` file before running this step.)"],"metadata":{"id":"JbGpX4Hnp7EL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soMq474-143F","outputId":"b9c0ff73-c9cd-4a4e-d388-ff5a33ed7526"},"outputs":[{"output_type":"stream","name":"stdout","text":["129\n","{'ten8qa9r'}\n","ten8qa9r\n"]}],"source":["# get the path of the webm file\n","path = '/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/No_Face_Movement_Data/videos/'\n","\n","# store all the file directories\n","all_files = os.listdir(path)\n","print(len(all_files))\n","\n","# get unique subjects\n","unique_subjects = set([filepath.split('_')[0] for filepath in os.listdir(path)])\n","print(unique_subjects)\n","\n","for subject in unique_subjects:\n","  all_data = {}\n","\n","  print(subject)\n","\n","  # check if the subject json file already exists. if so, skip the remainning body\n","  if os.path.isfile('/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/No_Face_Movement_Data/json/'+subject+'.json'):\n","    continue\n","   \n","  subject_data = []\n","  # go through all file directories in the webm file, find those that start with the subject name\n","  subject_files = fnmatch.filter(all_files, subject+'*')\n","  # manage every single file directory that starts with the subject name\n","  for filename in subject_files:\n","    # transform file name into an array\n","    fileinfo = filename.replace('.','_').split('_')\n","    # store relevant values\n","    subject = fileinfo[0]\n","    block = fileinfo[1]\n","    phase = fileinfo[2]\n","    x = fileinfo[3]\n","    y = fileinfo[4]\n","    meshfeatures = extract_mesh_from_video(path + filename)\n","    # create and append a dictionary to the exisiting array\n","    subject_data.append({\n","        'block': block,\n","        'phase': phase,\n","        'x': x,\n","        'y': y,\n","        'features': meshfeatures \n","    })\n","  # once the last for loop is over, assign the subject_data array as the value to the subject key\n","  all_data[subject] = subject_data\n","\n","  # export the json file for the subject to the drive\n","  with open('/content/drive/Shareddrives/URSI 2022/Eye Tracking ML/No_Face_Movement_Data/json/'+subject+'.json', 'w') as file:\n","    json.dump(all_data, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1659018156683,"user":{"displayName":"Oliravan Eswaramoorthy","userId":"13611592422418692717"},"user_tz":240},"id":"UneHehSTmjrl","outputId":"5552d852-e4dc-4788-a5c9-c6a0f10557bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'00r9ug5a',\n"," '03wral14',\n"," '0422erte',\n"," '0647xw1u',\n"," '0fzd0kcx',\n"," '0tam8hc6',\n"," '19207bos',\n"," '1a5wnle1',\n"," '1cj4gzmc',\n"," '1h1dsh7s',\n"," '1m7ba9w5',\n"," '1nqsmw2a',\n"," '28onkhh4',\n"," '2wjxblfh',\n"," '2ykovfwv',\n"," '3641lwa9',\n"," '3gg0jmrk',\n"," '3hhbcxwt',\n"," '3hhw02hk',\n"," '3jt1uk3n',\n"," '3sg17y69',\n"," '3swzt0jr',\n"," '3ypz3n33',\n"," '44shkkna',\n"," '459wtwlr',\n"," '4h62dlxl',\n"," '4n48phr9',\n"," '4u9ommb4',\n"," '4v1so2k2',\n"," '4w17oojf',\n"," '4ypfnlhr',\n"," '5lbbzkn1',\n"," '5yvugumm',\n"," '615fayp9',\n"," '6grjq52d',\n"," '6mg184ln',\n"," '6u7rnuc8',\n"," '6zkff4vo',\n"," '7080cnks',\n"," '76qjhxwz',\n"," '78beu8ch',\n"," '7ladzmrj',\n"," '8jnks6k4',\n"," '8vf1z9hb',\n"," '8wplohk7',\n"," '92kt8cg1',\n"," '92nmmc3e',\n"," '9bwnmhl0',\n"," '9rvutb4d',\n"," '9u78fe8u',\n"," '9v5cx8c3',\n"," 'awwje9eu',\n"," 'b3vrzhq2',\n"," 'b7dnzebl',\n"," 'bccxvpl3',\n"," 'bz3joge9',\n"," 'c00yahqp',\n"," 'c17pt575',\n"," 'c3xbcbds',\n"," 'c6p28g6e',\n"," 'c9yqeos6',\n"," 'cf2sd6an',\n"," 'chhzkjcf',\n"," 'cksx82sy',\n"," 'cxdc2ff8',\n"," 'dbz9hovl',\n"," 'df0x6wqj',\n"," 'djzl1p0t',\n"," 'dl75d10s',\n"," 'duavtnj5',\n"," 'e4b4puhb',\n"," 'e9dz6vtg',\n"," 'epsxz1ys',\n"," 'eqzcnrf9',\n"," 'ezv55ub8',\n"," 'f3vvo1jm',\n"," 'f83lfp24',\n"," 'f9ymrgsx',\n"," 'g2sf2265',\n"," 'g9twcnrm',\n"," 'gan392h7',\n"," 'glz22umw',\n"," 'gswk9uco',\n"," 'h1datqoo',\n"," 'h6o7cwa4',\n"," 'h9s0pk7o',\n"," 'hj0lwre6',\n"," 'jbgragfb',\n"," 'jf3uqlm0',\n"," 'jvuuv8xd',\n"," 'jxewh33c',\n"," 'jxk6nav6',\n"," 'k1e02f9k',\n"," 'k2rv03jx',\n"," 'kbswj194',\n"," 'ln1addz0',\n"," 'm254uvjd',\n"," 'm2wsxrcd',\n"," 'm92x5ume',\n"," 'mn1whlwc',\n"," 'n2mdoset',\n"," 'n4q2mn6b',\n"," 'n71uy3c3',\n"," 'n7flh0hx',\n"," 'nabd64xu',\n"," 'nh8ncnow',\n"," 'o16palgn',\n"," 'o1cekcwj',\n"," 'oc60g7j8',\n"," 'os6d3u63',\n"," 'owrk4hq7',\n"," 'ox846x8k',\n"," 'p8uogjwb',\n"," 'pa4f1gfc',\n"," 'q2rv1bj0',\n"," 'qgdqlv8f',\n"," 'qh68xdlr',\n"," 'qxbr8rf7',\n"," 'r1gvtesc',\n"," 'r30go9o8',\n"," 'r40zayr0',\n"," 'r80fz607',\n"," 'r8cvmbo1',\n"," 'roflfkva',\n"," 'rv1a94et',\n"," 'ryvtw1w8',\n"," 'sqgjnmj7',\n"," 't6r9gvx5',\n"," 't98z464d',\n"," 'to5p13vd',\n"," 'u0qhupu2',\n"," 'u7xm3z3q',\n"," 'ue9s8nux',\n"," 'us9ezsjl',\n"," 'v51xrc8u',\n"," 'v9zdhglz',\n"," 'vpboahj1',\n"," 'vx4khe0b',\n"," 'x1mkxvtr',\n"," 'xfkcdx69',\n"," 'xfxtbhvc',\n"," 'xm17fnhc',\n"," 'ybocfh08',\n"," 'yscaxtlm',\n"," 'z95kwcdt',\n"," 'z98nk7pa',\n"," 'zajruoul',\n"," 'zmdqq11j',\n"," 'zst3n4y4'}"]},"metadata":{},"execution_count":7}],"source":["unique_subjects"]}],"metadata":{"colab":{"provenance":[{"file_id":"1C9px-M7hROryjLWMlwo9Lrp0nen0MMod","timestamp":1658948043444}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}